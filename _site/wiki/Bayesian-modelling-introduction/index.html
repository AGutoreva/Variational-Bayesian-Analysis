<!DOCTYPE html>
<html>

      <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <title>Bayesian modeling: introduction</title>
        <meta name="viewport" content="width=device-width">
        <meta name="description" content="Write an awesome description for your new site here. It will appear in your document head meta (for Google search results) and in your feed.xml site description." />
        <link rel="canonical" href="/wiki/Bayesian-modelling-introduction//" />

        <!-- Custom CSS -->
        <link rel="stylesheet" href="/css/main.css">
        <!-- <link rel="stylesheet" href="/css/pygments_default.css">-->

<!-- icon font -->
        <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet">

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<!--<script type="text/javascript" src="/js/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/javascript" src="/js/jQuery.js"></script>
<script type="text/javascript" src="/js/toc.js"></script>-->
<script type="text/javascript">
$(document).ready(function() {
    $('.toc').toc();
});
</script>

<!--<script type="text/javascript" src="/js/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>-->

    </head>


    <body>

    <header class="site-header">

  <div class="wrap">

    <a class="site-title" href="/">VBA toolbox</a>

    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
           viewBox="0 0 18 15" enable-background="new 0 0 18 15" xml:space="preserve">
          <path fill="#505050" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0
            h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#505050" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484
            h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#505050" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0
            c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>
      <div class="trigger">
        <a class="page-link" href="/install"><i class="fa fa-download"></i> Install</a>
        <a class="page-link" href="/wiki"><i class="fa fa-book"></i> Wiki</a>
        <a class="page-link" href="/about"><i class="fa fa-mortar-board"></i> About</a>
      </div>
    </nav>

  </div>

</header>


    <div class="page-content">
      <div class="wrap">
      <div class="post">
  <header class="post-header">
  <h1 id="title"><a href="/wiki">WIKI</a>&nbsp;Bayesian modelling introduction</h1>
 </header>

  <article class="post-content">
    <hr/>
  <ul id="markdown-toc">
  <li><a href="#derivation-of-the-likelihood-function">Derivation of the likelihood function</a></li>
  <li><a href="#bayes-rule">Bayes’ rule</a></li>
  <li><a href="#statistical-tests-and-bayesian-model-comparison">Statistical tests and Bayesian model comparison</a></li>
</ul>

<h1 id="derivation-of-the-likelihood-function">Derivation of the likelihood function</h1>

<p>One usually starts with a quantitative assumption or model of how observations y are generated. Without loss of generality, this model possesses unknown parameters <script type="math/tex">\vartheta</script>, which are mapped through an observation function g:</p>

<script type="math/tex; mode=display">y= g(\vartheta)+\epsilon</script>

<p>where ε are model residuals or measurement noise. If the (physical) processes underlying ε were known, they would be included in the deterministic part of the model, i.e.: <script type="math/tex">\varepsilon \in g(\vartheta)</script>. Typically, we thus have to place statistical priors on <script type="math/tex">\varepsilon</script>, which eventually convey our lack of knowledge, as in “the noise is small”. This can be formalized as a probabilistic statement, such as: “the probability of observing big noise is small”. Under the central limit theorem, such prior would be equivalent to assuming the noise follows a normal distribution:</p>

<script type="math/tex; mode=display">p(\varepsilon\mid m)\propto exp\left(-\frac{1}{2\sigma^2}\varepsilon^2\right) \implies p(\lvert\epsilon\rvert>1.96\sigma\mid m) \approx 0.05</script>

<p>where <script type="math/tex">\sigma</script> is the noise’ standard deviation (it determines how big is “big”) and m is the so-called generative model. Equations 1 and 2 are compiled to derive a likelihood function <script type="math/tex">p(y\mid\vartheta,m)</script>, which specifies how likely it is to observe any particular set of observations y, given the unknown parameters <script type="math/tex">\vartheta</script> of the model m :</p>

<script type="math/tex; mode=display">p(y\mid\vartheta,m) = exp\left(-\frac{1}{2\sigma^2}(y-g(\vartheta))^2\right)</script>

<p>The intuition underlying the above derivation of the likelihood function can be generalized to any generative model <script type="math/tex">m</script>, whose parameters <script type="math/tex">\vartheta</script> simply control the statistical moments of the distribution <script type="math/tex">p(y\mid\vartheta,m)</script>. The key point here is that the likelihood function always derives from priors about observation mappings and measurement noise.</p>

<h1 id="bayes-rule">Bayes’ rule</h1>

<p>The likelihood function is the statistical construct that is common to both frequentist (classical) and bayesian inference approaches. However, bayesian approaches also require the definition of a prior distribution <script type="math/tex">p(\vartheta\mid m)</script> on model parameters <script type="math/tex">\vartheta</script>, which reflects knowledge about their likely range of values, before having observed the data y. As for priors about measurement noise, such priors can be (i) principled (e.g. certain parameters cannot have negative values), (ii) conservative (e.g. “shrinkage” priors that express the assumption that coupling parameters are small), or (iii) empirical (based on previous, independent measurements).<br />
Combining the priors and the likelihood function allows one, via Bayes’ Theorem, to derive both the marginal likelihood of the model (the so-called model evidence):</p>

<script type="math/tex; mode=display">p(y\mid m)=\int p(y\mid \vartheta,m)p(\vartheta\mid m)d\vartheta</script>

<p>and the posterior probability density function <script type="math/tex">p(\vartheta\mid,m)</script> over model parameters <script type="math/tex">\vartheta</script>:</p>

<script type="math/tex; mode=display">p(\vartheta\mid,m)=\frac{p(y\mid\vartheta,m)p(\vartheta\mid m)}{p(y\mid m)}</script>

<p>This is called “model inversion” or “solving the inverse problem”. The posterior density <script type="math/tex">p(\vartheta\mid y, m)</script>  quantifies how likely is any value of <script type="math/tex">\vartheta</script>, given the observed data y and the generative model <script type="math/tex">m</script>. It is used for inferring on “interesting” model parameters, by marginalizing over “nuisance” parameters. The model evidence <script type="math/tex">p(y\mid m)</script>  quantifies how likely is the observed data y under the generative model <script type="math/tex">m</script>. Another perspective on this is that <script type="math/tex">-\log p(y\mid m)</script> measures statistical surprise, i.e. how unpredictable was the observed data <script type="math/tex">y</script> under the model <script type="math/tex">m</script>. The model evidence accounts for model complexity, and thus penalizes models, whose predictions do not generalize easily (this is referred to as “Occam’s razor”). Under flat priors over models, it is used for model selection (by comparison with other models that differ in terms of either their likelihood or their prior density).</p>

<h1 id="statistical-tests-and-bayesian-model-comparison">Statistical tests and Bayesian model comparison</h1>

<p>Moments of the posterior density <script type="math/tex">p(\vartheta\mid y,m)</script> can be used to define parameter estimates (e.g., the posterior mean). Typically, as the quantity of available data increases, Bayesian parameter estimates effectively converge to frequentist (e.g. maximum likelihood) estimators. This is because the weight of the prior on any moment of the posterior distribution becomes negligible.</p>

<p>However, this (asymptotic) equivalence does not hold for model comparison. This is important, because model comparison has many application within a Bayesian framework. For example, when testing whether a parameter is zero, one effectively compares two hypotheses: the ‘null’, in which the parameter is fixed to zero, against the ‘alternative’, in which the parameter is allowed to vary.</p>

<p>According to the Neyman-Pearson lemma, the most powerful test to compare such two hypotheses or models is the likelihood-ratio test, i.e.:</p>

<script type="math/tex; mode=display">\frac{p(y\mid m_1)}{p(y\mid m_2)} > K</script>

<p>where <script type="math/tex">K</script> is set to satisfy a controlled statistical risk.<br />
This motivates the use of model evidences to perform statistical testing (e.g. testing the null) within a Bayesian framework. In fact, the quantity above is known as the ‘Bayes factor’, and is used whenever one wants to select between two models. More generally, the comparison of more than two models can be based upon their model evidence, which quantifies the plausibility of the data under any model.</p>

<p>The critical thing to note is that the model evidence is not a simple measure of model fit: there is an inherent penalization for model complexity. Let us note that the model evidence is maximal whenever the information in the data about model parameters is the same as that of the prior density. In other words, a good model is a model that is confirmed by the data. A simple model has tight priors: to the limit, the simplest of all models has no unknown parameters (infinite precision priors). This means that there is a complexity cost to changing one’s belief on parameters to explain data.</p>

<p>In brief, the model evidence is nothing else than the data likelihood, given any model. Bayes’ rule can then be used to perform inference on models, by deriving the posterior distribution over models, i.e.:</p>

<script type="math/tex; mode=display">p(m\mid y)=\frac{p(y\mid m)p(m)}{p(y)}</script>

<p>where <script type="math/tex">p(y)</script> is the probability of data given all possible models</p>

<script type="math/tex; mode=display">p(y)=\sum _m p(y\mid m)p(m)</script>

<p>The term <script type="math/tex">p(m)</script> is the prior probability on model m. Typically, noninformative priors are used and the equation above is driven solely by the Bayes’ factor.</p>

<p>As for any statistical test, a threshold has to be set for deciding whether a model is “better” than another one. This threshold can be chosen similarly to classical statistics, i.e. on the basis of some acceptable statistical risk. It turns out that the probability of making a model selection error is 1 minus the posterior probability of the selected model. If this probability has to be controlled at e.g., 0.05, then one “selects” a model only if its posterior probability exceeds 0.95. When comparing two models with each other, this corresponds to a threshold of <script type="math/tex">K=20</script> on the Bayes’ factor.</p>

<p>This logic applies for any set of models, given any data. The only constraint is that model evidences have to be evaluated on the same data  set.</p>

<p>Practically speaking, the Bayes’ factor induces three types of statistical decisions:</p>

<ul>
  <li><script type="math/tex">K>20</script>:      model <script type="math/tex">m_1</script> is selected</li>
  <li><script type="math/tex">% <![CDATA[
0.05<K<20 %]]></script>: no model is selected</li>
  <li><script type="math/tex">% <![CDATA[
K<0.05 %]]></script>:    model <script type="math/tex">m_2</script> is selected</li>
</ul>

 <hr/>
  <div class='return_link'><a href="#title"><i class="fa fa-chevron-up"></i> back to top</a></div>
  </article>


</div>


      </div>
    </div>

    <footer class="site-footer">

  <div class="wrap">


    <div class="footer-col-1 column">
        <h2 class="footer-heading">Participate to the VBA-toolbox!</h2>

          <ul>
        <li>
           <i class="fa fa-github-square fa-fw "></i>
          <a href="https://github.com/MBB-team/VBA-toolbox/fork">fork on Github</a>
        </li>
        <li>
          <i class="fa fa-edit fa-fw "></i>
          <a href="https://github.com/MBB-team/VBA-toolbox/issues">post a request</a>
        </li>
        </ul>

    </div>

    <div class="footer-col-2 column">
     <ul>
        <li>Jean DAUNIZEAU</li>
        <li><a href="mailto:jean.daunizeau@gmail.com">jean.daunizeau[at]gmail.com</a></li>
      </ul>
      <ul>
        <li>Lionel RIGOUX</li>
        <li><a href="mailto:lionel.rigoux@gmail.com">lionel.rigoux[at]gmail.com</a></li>
      </ul>

     </div>

    <div class="footer-col-3 column">
<p>J. Daunizeau, V. Adam, L. Rigoux (2014), VBA: a probabilistic treatment of nonlinear models for neurobiological and behavioural data. PLoS Comp Biol 10(1): e1003441.</p>
    </div>

  </div>

</footer>


    </body>

</html>
